# Evaluation Results

*Last generated on: 2021-11-11* (YYYY-MM-DD)

## jax2tf --> TFLite

### The Flax Examples
[URL to examples](https://github.com/google/flax/tree/main/examples)

Description: List of examples maintained by the Flax team.
These exampls are representative for what the average ML researcher is interested in.

| Example | Result | Error Message |
| --- | --- | --- |
| imagenet | SUCCESS |
| lm1b | FAIL | ValueError('Numerical difference: jax_result=[[[ 1.0656209e+00  9.3210316e-01 -7.5562042e-01  5.7160920e-01\n    4.7576640e-04 -8.3388436e-01 -6.6835815e-01  8.1217813e-01]]\n\n [[ 1.0656208e+00  9.3210304e-01 -7.5562042e-01  5.7160914e-01\n    4.7582600e-04 -8.3388436e-01 -6.6835815e-01  8.1217837e-01]]] vs tflite_result=[[[ 1.0656209e+00  9.3210316e-01 -7.5562030e-01  5.7160920e-01\n    4.7570679e-04 -8.3388448e-01 -6.6835809e-01  8.1217837e-01]]\n\n [[ 1.0656209e+00  9.3210316e-01 -7.5562030e-01  5.7160920e-01\n    4.7570679e-04 -8.3388448e-01 -6.6835809e-01  8.1217837e-01]]]')
| mnist | SUCCESS |
| nlp_seq | SUCCESS |
| pixelcnn++ | FAIL | ValueError('Numerical difference: jax_result=[[[[-1.42588705e-01  4.43906128e-01 -4.43267524e-01 ...  2.41633713e-01\n     4.30841953e-01 -3.73984545e-01]\n   [-4.39649850e-01  5.52693188e-01 -2.85841674e-01 ... -4.82337102e-02\n     2.57767290e-01 -1.49030924e-01]\n   [-1.11790448e-01  4.16247308e-01 -4.37891722e-01 ...  2.55762637e-01\n     4.27294075e-01 -3.77151638e-01]\n   ...\n   [-3.12222362e-01  6.24503791e-01 -5.10304689e-01 ...  1.91281274e-01\n     4.87456709e-01 -3.91308606e-01]\n   [-5.44569135e-01  6.36496902e-01 -2.90352285e-01 ... -1.06496125e-01\n     2.56181568e-01 -1.25419632e-01]\n   [-2.74163693e-01  4.84380186e-01 -3.63327265e-01 ...  1.05749786e-01\n     3.44067216e-01 -2.64860481e-01]]\n\n  [[-2.40709454e-01  5.66605926e-01 -5.06200612e-01 ...  2.30237216e-01\n     4.87517625e-01 -4.06445533e-01]\n   [-5.57913125e-01  7.04271495e-01 -3.66582096e-01 ... -5.83822057e-02\n     3.30919504e-01 -1.92696482e-01]\n   [-5.57003498e-01  7.44562387e-01 -4.20874745e-01 ... -1.80031136e-02\n     3.84750396e-01 -2.43371978e-01]\n   ...\n   [ 3.23703378e-01  8.85252953e-02 -4.45828974e-01 ...  5.17160952e-01\n     4.60283160e-01 -4.99921381e-01]\n   [-7.84780085e-02  4.18959796e-01 -4.75297749e-01 ...  3.02764535e-01\n     4.66267854e-01 -4.20726597e-01]\n   [-3.81832868e-01  2.57512122e-01  4.64698970e-02 ... -2.58186400e-01\n    -6.80610538e-02  1.44345522e-01]]\n\n  [[-5.36303878e-01  6.82846010e-01 -3.60135853e-01 ... -5.04315346e-02\n     3.25781107e-01 -1.92434311e-01]\n   [-4.13200080e-01  6.43507600e-01 -4.32981879e-01 ...  7.52745569e-02\n     4.05040056e-01 -2.92723596e-01]\n   [-5.08693814e-01  7.07601190e-01 -4.20951635e-01 ...  1.04043037e-02\n     3.87613952e-01 -2.56244481e-01]\n   ...\n   [-4.62354958e-01  6.37909293e-01 -3.75672787e-01 ...  4.36854362e-03\n     3.45437586e-01 -2.26462051e-01]\n   [-5.25030494e-01  5.88392317e-01 -2.46465072e-01 ... -1.27238512e-01\n     2.13837355e-01 -8.98284614e-02]\n   [-3.39070499e-01  6.06849134e-01 -4.59667653e-01 ...  1.38362765e-01\n     4.35750186e-01 -3.37155759e-01]]\n\n  ...\n\n  [[-1.80023760e-01 -2.04962850e-01  4.54223275e-01 ... -4.39002693e-01\n    -4.60308641e-01  4.69647795e-01]\n   [-3.61009240e-02  3.46753567e-01 -4.22667176e-01 ...  2.89008379e-01\n     4.16580796e-01 -3.83065075e-01]\n   [-1.97503224e-01  2.04578102e-01 -7.05133975e-02 ... -6.41571060e-02\n     5.84497154e-02 -1.31680667e-02]\n   ...\n   [ 6.29594445e-01 -2.10933590e+00  2.15497446e+00 ... -1.21205044e+00\n    -2.09823871e+00  1.83500791e+00]\n   [ 6.24921799e-01 -2.09842682e+00  2.14526725e+00 ... -1.20766854e+00\n    -2.08889318e+00  1.82722878e+00]\n   [ 8.55360699e+00 -6.76110506e+00  2.73621976e-01 ...  4.81894445e+00\n     2.22493500e-01 -2.01234460e+00]]\n\n  [[ 6.28618002e-01 -1.64117575e-01 -4.20674622e-01 ...  6.77641809e-01\n     4.52959955e-01 -5.57350397e-01]\n   [-5.37976146e-01  6.62559867e-01 -3.31567317e-01 ... -7.23793134e-02\n     2.97386676e-01 -1.65452838e-01]\n   [ 8.36412668e-01 -3.35356057e-01 -4.04769182e-01 ...  7.87914932e-01\n     4.49194461e-01 -5.97636402e-01]\n   ...\n   [-1.32435262e-01  4.79223609e-01 -5.00355184e-01 ...  2.89488912e-01\n     4.87974793e-01 -4.29705858e-01]\n   [ 9.67554951e+00 -7.69631195e+00  3.73595059e-01 ...  5.40399551e+00\n     1.88200951e-01 -2.21676683e+00]\n   [-3.34489554e-01  1.41441345e-01  1.52162671e-01 ... -3.07970345e-01\n    -1.70021206e-01  2.29982585e-01]]\n\n  [[-5.73506176e-01  8.37986112e-01 -5.27873397e-01 ...  5.08383326e-02\n     4.89783496e-01 -3.38394195e-01]\n   [-1.21431410e-01  4.68201816e-01 -4.96924907e-01 ...  2.93429136e-01\n     4.85211879e-01 -4.29435134e-01]\n   [-4.99263555e-01  5.34260869e-01 -2.00916573e-01 ... -1.45544931e-01\n     1.70206934e-01 -5.43444455e-02]\n   ...\n   [ 5.05807877e-01 -8.23336840e-02 -4.04350072e-01 ...  5.93589127e-01\n     4.29704130e-01 -5.09643853e-01]\n   [-6.71721458e-01  9.28758919e-01 -5.48419893e-01 ...  8.27892870e-03\n     5.04468620e-01 -3.31455648e-01]\n   [ 4.47143412e+00 -3.35836935e+00 -9.01285410e-02 ...  2.69024301e+00\n     3.47266555e-01 -1.26855779e+00]]]] vs tflite_result=[[[[-1.4258870e-01  4.4390613e-01 -4.4326755e-01 ...  2.4163373e-01\n     4.3084195e-01 -3.7398458e-01]\n   [-4.3964982e-01  5.5269313e-01 -2.8584164e-01 ... -4.8233725e-02\n     2.5776726e-01 -1.4903089e-01]\n   [-1.1179039e-01  4.1624728e-01 -4.3789172e-01 ...  2.5576267e-01\n     4.2729408e-01 -3.7715167e-01]\n   ...\n   [-3.1222239e-01  6.2450385e-01 -5.1030469e-01 ...  1.9128124e-01\n     4.8745668e-01 -3.9130858e-01]\n   [-5.4456913e-01  6.3649696e-01 -2.9035234e-01 ... -1.0649611e-01\n     2.5618160e-01 -1.2541966e-01]\n   [-2.7416372e-01  4.8438025e-01 -3.6332729e-01 ...  1.0574977e-01\n     3.4406722e-01 -2.6486048e-01]]\n\n  [[-2.4070942e-01  5.6660587e-01 -5.0620061e-01 ...  2.3023726e-01\n     4.8751763e-01 -4.0644553e-01]\n   [-5.5791312e-01  7.0427150e-01 -3.6658210e-01 ... -5.8382221e-02\n     3.3091947e-01 -1.9269648e-01]\n   [-5.5700350e-01  7.4456239e-01 -4.2087471e-01 ... -1.8003114e-02\n     3.8475040e-01 -2.4337198e-01]\n   ...\n   [ 3.2370314e-01  8.8525474e-02 -4.4582897e-01 ...  5.1716077e-01\n     4.6028316e-01 -4.9992132e-01]\n   [-7.8478158e-02  4.1895992e-01 -4.7529775e-01 ...  3.0276448e-01\n     4.6626785e-01 -4.2072654e-01]\n   [-3.8183290e-01  2.5751221e-01  4.6469748e-02 ... -2.5818634e-01\n    -6.8060935e-02  1.4434543e-01]]\n\n  [[-5.3630388e-01  6.8284601e-01 -3.6013585e-01 ... -5.0431535e-02\n     3.2578111e-01 -1.9243431e-01]\n   [-4.1320011e-01  6.4350760e-01 -4.3298191e-01 ...  7.5274557e-02\n     4.0504006e-01 -2.9272363e-01]\n   [-5.0869381e-01  7.0760125e-01 -4.2095163e-01 ...  1.0404289e-02\n     3.8761395e-01 -2.5624445e-01]\n   ...\n   [-4.6235496e-01  6.3790929e-01 -3.7567282e-01 ...  4.3685548e-03\n     3.4543759e-01 -2.2646205e-01]\n   [-5.2503049e-01  5.8839238e-01 -2.4646513e-01 ... -1.2723847e-01\n     2.1383741e-01 -8.9828506e-02]\n   [-3.3907056e-01  6.0684919e-01 -4.5966765e-01 ...  1.3836275e-01\n     4.3575019e-01 -3.3715576e-01]]\n\n  ...\n\n  [[-1.8002376e-01 -2.0496285e-01  4.5422316e-01 ... -4.3900269e-01\n    -4.6030858e-01  4.6964785e-01]\n   [-3.6100924e-02  3.4675357e-01 -4.2266718e-01 ...  2.8900838e-01\n     4.1658083e-01 -3.8306510e-01]\n   [-1.9750324e-01  2.0457810e-01 -7.0513427e-02 ... -6.4157099e-02\n     5.8449715e-02 -1.3168067e-02]\n   ...\n   [ 6.2959445e-01 -2.1093359e+00  2.1549742e+00 ... -1.2120504e+00\n    -2.0982387e+00  1.8350079e+00]\n   [ 6.2492168e-01 -2.0984268e+00  2.1452668e+00 ... -1.2076684e+00\n    -2.0888929e+00  1.8272285e+00]\n   [ 8.5536060e+00 -6.7611046e+00  2.7362186e-01 ...  4.8189440e+00\n     2.2249353e-01 -2.0123446e+00]]\n\n  [[ 6.2861800e-01 -1.6411757e-01 -4.2067462e-01 ...  6.7764181e-01\n     4.5295995e-01 -5.5735040e-01]\n   [-5.3797615e-01  6.6255987e-01 -3.3156732e-01 ... -7.2379321e-02\n     2.9738668e-01 -1.6545282e-01]\n   [ 8.3641267e-01 -3.3535618e-01 -4.0476918e-01 ...  7.8791493e-01\n     4.4919446e-01 -5.9763640e-01]\n   ...\n   [-1.3243538e-01  4.7922373e-01 -5.0035524e-01 ...  2.8948885e-01\n     4.8797479e-01 -4.2970586e-01]\n   [ 9.6755476e+00 -7.6963100e+00  3.7359476e-01 ...  5.4039946e+00\n     1.8820101e-01 -2.2167664e+00]\n   [-3.3448958e-01  1.4144140e-01  1.5216261e-01 ... -3.0797035e-01\n    -1.7002115e-01  2.2998253e-01]]\n\n  [[-5.7350618e-01  8.3798611e-01 -5.2787340e-01 ...  5.0838351e-02\n     4.8978353e-01 -3.3839419e-01]\n   [-1.2143147e-01  4.6820188e-01 -4.9692491e-01 ...  2.9342908e-01\n     4.8521188e-01 -4.2943513e-01]\n   [-4.9926355e-01  5.3426087e-01 -2.0091659e-01 ... -1.4554493e-01\n     1.7020695e-01 -5.4344445e-02]\n   ...\n   [ 5.0580800e-01 -8.2333684e-02 -4.0435010e-01 ...  5.9358925e-01\n     4.2970419e-01 -5.0964397e-01]\n   [-6.7172146e-01  9.2875892e-01 -5.4841989e-01 ...  8.2789287e-03\n     5.0446862e-01 -3.3145565e-01]\n   [ 4.4714332e+00 -3.3583684e+00 -9.0128660e-02 ...  2.6902425e+00\n     3.4726658e-01 -1.2685575e+00]]]]')
| ppo | FAIL | SUCCESS |
| seq2seq | SUCCESS |
| sst2 | SUCCESS |
| vae | SUCCESS |
| wmt | SUCCESS |

## jax2tf --> TFjs

### The Flax Examples
[URL to examples](https://github.com/google/flax/tree/main/examples)

Description: List of examples maintained by the Flax team.
These exampls are representative for what the average ML researcher is interested in.

| Example | Result | Error Message |
| --- | --- | --- |
| imagenet | SUCCESS |
| lm1b | FAIL | ValueError("in user code:\n\n\n    ValueError: Got a non-Tensor value FrozenDict({\n        cache: {\n            decoder: {\n                encoderdecoderblock_0: {\n                    SelfAttention_0: {\n                        cache_index: <tf.Tensor 'StatefulPartitionedCall:1' shape=() dtype=int32>,\n                        cached_key: <tf.Tensor 'StatefulPartitionedCall:2' shape=(2, 1, 1, 2) dtype=float32>,\n                        cached_value: <tf.Tensor 'StatefulPartitionedCall:3' shape=(2, 1, 1, 2) dtype=float32>,\n                    },\n                },\n                posembed_output: {\n                    cache_index: <tf.Tensor 'StatefulPartitionedCall:4' shape=() dtype=uint32>,\n                },\n            },\n        },\n    }) for key 'output_1' in the output of the function __inference_<lambda>_74438 used to generate the SavedModel signature 'serving_default'. Outputs for functions used as signatures must be a single Tensor, a sequence of Tensors, or a dictionary from string to Tensor.\n")
| mnist | SUCCESS |
| nlp_seq | FAIL | ValueError("Error when tracing gradients for SavedModel.\n\nSee the stack trace above to see the error that was raised when converting a gradient function to a concrete function. You may need to update the custom gradient, or disable saving gradients with the option tf.saved_model.SaveOptions(custom_gradients=False).\n\tProblematic op name: IdentityN\n\tGradient inputs: (<tf.Tensor 'AddV2_12:0' shape=(2, 1, 8) dtype=float32>, <tf.Tensor 'jax2tf_arg_0:0' shape=(8,) dtype=float32>, <tf.Tensor 'jax2tf_arg_1:0' shape=(4, 8) dtype=float32>, <tf.Tensor 'jax2tf_arg_2:0' shape=(4,) dtype=float32>, <tf.Tensor 'jax2tf_arg_3:0' shape=(4,) dtype=float32>, <tf.Tensor 'jax2tf_arg_4:0' shape=(4,) dtype=float32>, <tf.Tensor 'jax2tf_arg_5:0' shape=(4,) dtype=float32>, <tf.Tensor 'jax2tf_arg_6:0' shape=(2,) dtype=float32>, <tf.Tensor 'jax2tf_arg_7:0' shape=(4, 2) dtype=float32>, <tf.Tensor 'jax2tf_arg_8:0' shape=(4,) dtype=float32>, <tf.Tensor 'jax2tf_arg_9:0' shape=(2, 4) dtype=float32>, <tf.Tensor 'jax2tf_arg_10:0' shape=(4, 1, 2) dtype=float32>, <tf.Tensor 'jax2tf_arg_11:0' shape=(1, 2, 4) dtype=float32>, <tf.Tensor 'jax2tf_arg_12:0' shape=(4, 1, 2) dtype=float32>, <tf.Tensor 'jax2tf_arg_13:0' shape=(4, 1, 2) dtype=float32>, <tf.Tensor 'jax2tf_arg_14:0' shape=(4,) dtype=float32>, <tf.Tensor 'jax2tf_arg_15:0' shape=(4,) dtype=float32>, <tf.Tensor 'jax2tf_arg_16:0' shape=(8, 4) dtype=float32>, <tf.Tensor 'jax2tf_arg_17:0' shape=(2, 1) dtype=float32>)")
| pixelcnn++ | SUCCESS |
| ppo | SUCCESS |
| seq2seq | FAIL | ValueError('Unsupported Ops in the model before optimization\nBitcast, BitwiseAnd, BitwiseOr, LeftShift, BitwiseXor, RightShift')
| sst2 | FAIL | ValueError('Unsupported Ops in the model before optimization\nBitwiseAnd')
| vae | SUCCESS |
| wmt | FAIL | ValueError("in user code:\n\n\n    ValueError: Got a non-Tensor value FrozenDict({\n        cache: {\n            decoder: {\n                encoderdecoderblock_0: {\n                    SelfAttention_0: {\n                        cache_index: <tf.Tensor 'StatefulPartitionedCall:1' shape=() dtype=int32>,\n                        cached_key: <tf.Tensor 'StatefulPartitionedCall:2' shape=(2, 1, 1, 2) dtype=float32>,\n                        cached_value: <tf.Tensor 'StatefulPartitionedCall:3' shape=(2, 1, 1, 2) dtype=float32>,\n                    },\n                },\n                posembed_output: {\n                    cache_index: <tf.Tensor 'StatefulPartitionedCall:4' shape=() dtype=uint32>,\n                },\n            },\n        },\n    }) for key 'output_1' in the output of the function __inference_<lambda>_229578 used to generate the SavedModel signature 'serving_default'. Outputs for functions used as signatures must be a single Tensor, a sequence of Tensors, or a dictionary from string to Tensor.\n")

## Table generation

See `examples_test.py` for instructions on how to regenerate this table.
